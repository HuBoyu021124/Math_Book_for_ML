## 7.1 基于梯度下降的优化
现在考虑求解一个实值函数最小值的问题：
$$
\min\limits_{\boldsymbol{x}}~f(\boldsymbol{x}), \tag{7.4}
$$
其中 $f: \mathbb{R}^{d} \rightarrow \mathbb{R}$ 是一个函数，它刻画了我们手中的机器学习问题。我们假设函数 $f$ 是可微的，并且我们无法找到上述问题的解析解。

梯度下降是一个一阶优化算法。它的每次迭代都将估计点做一个正比于函数在该点处的负梯度向量的移动，以逐步找到一个局部最小值点。回顾第 5.1 节，梯度方向是函数值增长最快的方向。另一个有用的直观理解是考虑函数处于某个特定值处的那组线（即 $f(\boldsymbol{x})=c$ ，其中某个值 $c \in \mathbb{R}$ ），这些线被称为等高线。梯度方向与我们希望优化的函数的等高线方向正交。

让我们考虑多变量函数。想象一个曲面（由函数 $f(\boldsymbol{x})$ 描述），并设想一个球从某个特定位置 $\boldsymbol{x}_0$ 开始。当球被释放时，它会沿着最陡峭的下坡方向向下滚动。梯度下降利用了这样一个事实：从 $\boldsymbol{x}_0$ 出发，若朝着函数 $f$ 在 $\boldsymbol{x}_0$ 处负的梯度方向 $-\left((\nabla f)(\boldsymbol{x}_0)\right)^{\top}$ 移动，$f(\boldsymbol{x}_0)$ 的值将最快地减小。本书假设所涉及的函数都是可微的，并引导读者参考第 7.4 节中更一般的设置。于是假如我们考虑下面的更新：
$$
\boldsymbol{x}_{1} = \boldsymbol{x}_{0} - \gamma \big[ (\nabla f)(\boldsymbol{x}_{0}) \big] ^{\top} \tag{7.5}
$$
若 $\gamma \geqslant 0$ 是一个很小的 **步长**，就有 $f(\boldsymbol{x}_{1}) \leqslant f(\boldsymbol{x}_{0})$。注意我们在梯度的部分使用了转置记号，这是因为我们在本书中默认梯度时行向量——如果不转置的话维度对不上。

有了这个发现，我们就能提出一个简单的梯度下降算法：我们想要找到一个函数 $f: \mathbb{R}^{n} \rightarrow \mathbb{R}, \boldsymbol{x} \mapsto f(\boldsymbol{x})$ 的局部最优解 $f(\boldsymbol{x}_{*})$ ，我们从一个初始估计 $\boldsymbol{x}_{0}$ 开始，然后按照下面的更新规则不断迭代
$$
\boldsymbol{x}_{i+1} = \boldsymbol{x}_{i} - \gamma_{i} \big[ (\nabla f)(\boldsymbol{x}_{i}) \big] ^{\top} \tag{7.6}
$$
假设我们每次迭代选择的步长足够合适，我们得到的序列就是一个下降的 “链”：$f(\boldsymbol{x}_{0}) \geqslant f(\boldsymbol{x}_{1}) \geqslant \cdots$ 它最终会趋于函数的局部最小值。


> **示例 7.1**
> 考虑下面的二维二次函数
> $$f\left(\begin{bmatrix}x_{1}\\x_{2}\end{bmatrix}\right) = \frac{1}{2}\begin{bmatrix}x_{1}\\x_{2}\end{bmatrix}^{\top}\begin{bmatrix}2&1\\1&20\end{bmatrix}\begin{bmatrix}x_{1}\\x_{2}\end{bmatrix} - \begin{bmatrix}5\\3\end{bmatrix}^{\top}\begin{bmatrix}x_{1}\\x_{2}\end{bmatrix}\tag{7.7}$$
> 它对 $\boldsymbol{x}$ 的梯度是 $$\nabla f\left(\begin{bmatrix}x_{1}\\x_{2}\end{bmatrix}\right) = \begin{bmatrix}x_{1}\\x_{2}\end{bmatrix}^{\top}\begin{bmatrix}2&1\\1&20\end{bmatrix} - \begin{bmatrix}5\\3\end{bmatrix}^{\top}\tag{7.8}$$
> 如图 7.3 所示，我们从初始估计 $\boldsymbol{x}_{0} = [-3, -1]^{\top}$ 开始用公式 (7.6) 不断迭代，以得到一个收敛于函数最小值的估计值序列。可见 $\boldsymbol{x}_{0}$ 处的负梯度指向右上方，从而得到第二个估计 $\boldsymbol{x}_{1} = [-1.98, 1.21]^{\top}$ （令 $\gamma = 0.085$，并将 $\boldsymbol{x}_{0}$ 代入 (7.8) ）。再迭代一次，我们得到 $\boldsymbol{x}_{2} = [-1.32, -0.42]^{\top}$，以此类推。
> <center><img src="ch7/attachments/Pasted%20image%2020250630213059.png" alt="alt text" style="zoom:50%;"></center>
> <center>图 7.3 梯度下降算法的示例</center>

> **注释**
> 梯度下降算法趋近局部最小值的速度可以很慢，它的渐近收敛速度弱于很多其他算法。在面临一些性质不甚好的凸函数时，我们可以想象一个从很长但很窄的斜坡滚下的球：梯度下降的更新轨迹将会是像图 7.3 那样的锯齿形，每次更新的方向甚至会与该点与局部最小值点的直接连线几乎垂直。

### 7.1.1 步长（学习率）

前文提到，步长大小在梯度下降算法中十分重要：如果步长太小，梯度下降的速度会很慢；如果步长太大，梯度下降算法有可能射出原本的 “峡谷” 区域，难以收敛，甚至发散。解决方法之一——动量法是通过平滑不稳定的更新行为并抑制更新中的震荡现象的方法，我们将在下一节介绍它。

另一种解决方法是所谓 **自适应梯度法**。它们在每次梯度更新时都会根据函数在局部的行为对梯度进行缩放。下面是两个简单的启发方法 (Toussaint, 2012)
* 梯度更新后函数值变大了，这说明步长太大走得太远。回退这一步然后选一个更小的步长
* 梯度更新后函数值变小了，说明还可以走更远，因此可以尝试更大的步长
虽然 “回退” 这个做法看起来浪费资源，但这可以保证每次更新都会降低目标函数值。

> **示例 7.2（解线性方程）**
> 加入我们用的范数是 Euclidean 范数，当我们解像 $\boldsymbol{A}\boldsymbol{x} = \boldsymbol{b}$ 这样的方程时，我们其实是通过找最小化 $$ \| \boldsymbol{A}\boldsymbol{x} - \boldsymbol{b} \| ^{2} = (\boldsymbol{A}\boldsymbol{x} - \boldsymbol{b})^{\top}(\boldsymbol{A}\boldsymbol{x} - \boldsymbol{b})\tag{7.9}$$以找到 $\boldsymbol{A}\boldsymbol{x} - \boldsymbol{b} = \boldsymbol{0}$ 的近似解 $\boldsymbol{x}_{*}$ 来完成的。公式 (7.9) 对 $\boldsymbol{x}$ 的梯度是 $$ \nabla_{\boldsymbol{x}} = 2(\boldsymbol{A}\boldsymbol{x} - \boldsymbol{b})^{\top}\boldsymbol{A}, \tag{7.10} $$ 我们可以用它直接导出梯度下降算法。但对于这个例子本身，我们有一个解析解——令梯度为零就可得到。我们将在第九章介绍更多求解平方损失的内容。

> **注释**
> 用上述方法解 $\boldsymbol{A}\boldsymbol{x} = \boldsymbol{b}$ 形式的方程在某些情况下并不高效。梯度下降算法的收敛速度取决于矩阵的 **条件数** $\displaystyle \kappa = \frac{\sigma(\boldsymbol{A})_{\max}}{\sigma(\boldsymbol{A})_{\min}}$，它的值为矩阵 $\boldsymbol{A}$ 的最大奇异值 （见 4.5  节）和最小奇异值之比。换句话说，条件数刻画了目标函数最陡峭的方向和最平缓方向的 "差距"。这和我们之前提到的情形相似：窄且长的 “峡谷” 对应着高的条件数：沿着峡谷行进的方向坡度平缓，而垂直于它的方向坡度陡峭。实际操作中我们不会直接求解 $\boldsymbol{A}\boldsymbol{x} = \boldsymbol{b}$，而是转而求解 $\boldsymbol{P}^{-1}(\boldsymbol{A}\boldsymbol{x} - \boldsymbol{b}) = 0$，其中 $\boldsymbol{P}$ 称为 **预条件子**，它可以降低新得到的线性方程系数矩阵的条件数，且 $\boldsymbol{P}$ 本身需要容易得到。更多信息请参见 Boyd and Vandenberghe (2004，第九章)。

### 7.1.2 动量梯度下降
$$
\begin{align}
\boldsymbol{x}_{i+1} &= \boldsymbol{x}_{i} - \gamma_{i} \big[ (\nabla f)(\boldsymbol{x}_{i}) \big] ^{\top} + \alpha\Delta \boldsymbol{x}_{i} \tag{7.11}\\
\Delta \boldsymbol{x}_{i} &= \boldsymbol{x}_{i} - \boldsymbol{x}_{i-1} = \alpha\Delta \boldsymbol{x}_{i-1} - \gamma_{i-1}\big[ (\nabla f)(\boldsymbol{x}_{i-1}) \big] ^{\top}, \tag{7.12}
\end{align}
$$


### 7.1.3 随机梯度下降
$$
L(\boldsymbol{\theta}) = \sum\limits_{n=1}^{N} L_{n}(\boldsymbol{\theta})\tag{7.13}
$$
$$
L(\boldsymbol{\theta}) = -\sum\limits_{n=1}^{N} \log p(y_{n}|\boldsymbol{x}_{n}, \boldsymbol{\theta}) \tag{7.14}
$$
$$
\boldsymbol{\theta}_{i+1} + \boldsymbol{\theta}_{i} = \gamma_{i}\big[ \nabla L(\boldsymbol{\theta}_{i}) \big] ^{\top} = \boldsymbol{\theta}_{i} - \gamma_{i}\sum\limits_{n=1}^{N} \big[ \nabla L_{n}(\boldsymbol{\theta}_{i}) \big] ^{\top}\tag{7.15}
$$
