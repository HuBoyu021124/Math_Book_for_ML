## 6.3 加法规则、乘法规则与贝叶斯公式

我们将概率论视为逻辑推理的扩展。正如我们在第$\dot{6}.1.1$节中讨论的那样，这里提出的概率规则自然而然地满足了所需条件（Jaynes, 2003, 第2章）。概率建模（第8.4节）为设计机器学习方法提供了原则性的基础。一旦我们定义了与数据和我们问题的不确定性相对应的概率分布（第6.2节），就会发现只有两个基本规则：加法规则和乘法规则。

回顾式（6.9），$p(x,y)$是两个随机变量$x,y$的联合分布。分布$p(\boldsymbol{x})$和$p(\boldsymbol{y})$是相应的边缘分布，而$p(y\mid x)$是在给定$x$的条件下$y$的条件分布。根据第6.2节中离散和连续随机变量的边缘和条件概率的定义，我们现在可以介绍概率论中的两个基本规则。

第一个规则，加法规则，表明

$$p(\boldsymbol{x})=\left\{\begin{array}{ll}\displaystyle\sum_{\boldsymbol{y}\in\mathcal{Y}}p(\boldsymbol{x},\boldsymbol{y})&\quad\text{如果}\:\boldsymbol{y}\:\text{是离散的}\\\\\displaystyle\int_{\mathcal{Y}}p(\boldsymbol{x},\boldsymbol{y})\mathrm{d}\boldsymbol{y}&\quad\text{如果}\:\boldsymbol{y}\:\text{是连续的}\end{array}\right.,$$

(6.20)

其中$\mathcal{Y}$是随机变量$Y$的目标空间的状态。这意味着我们对随机变量$Y$的状态集$y$进行求和（或积分）。加法规则也被称为边缘化属性。加法规则将联合分布与边缘分布联系起来。一般来说，当联合分布包含两个以上的随机变量时，加法规则可以应用于随机变量的任何子集，从而得到可能包含多个随机变量的边缘分布。更具体地说，如果$x=[x_1,\ldots,x_D]^\top$，我们通过反复应用加法规则（其中我们积分/求和出除了$x_i$之外的所有随机变量，用$\backslash i$表示“除了$i$之外的所有”），得到边缘分布

$$p(x_i)=\int p(x_1,\ldots,x_D)\mathrm{d}\boldsymbol{x}_{\setminus i}$$

(6.21)

**备注**。概率建模中的许多计算挑战都源于加法规则的应用。当存在许多变量或具有许多状态的离散变量时，加法规则归结为执行高维求和或积分。从计算的角度来看，执行高维求和或积分通常是困难的，因为目前没有已知的多项式时间算法可以精确计算它们。

第二条规则，称为**乘法规则**，它通过以下方式将联合分布与条件分布联系起来：

(6.22)

$$p(\boldsymbol{x},\boldsymbol{y})=p(\boldsymbol{y}\mid\boldsymbol{x})p(\boldsymbol{x})\:.$$

乘法规则可以理解为，任何两个随机变量的联合分布都可以分解为（写成乘积形式）另外两个分布。这两个因子分别是第一个随机变量的边缘分布$p(x)$，以及给定第一个随机变量时第二个随机变量的条件分布$p(\boldsymbol{y}\mid\boldsymbol{x})$。由于在$p(x,y)$中随机变量的顺序是任意的，乘法规则也意味着$p(\boldsymbol{x},\boldsymbol{y})=p(\boldsymbol{x}\mid\boldsymbol{y})p(\boldsymbol{y})$。准确地说，（6.22）是用离散随机变量的概率质量函数来表示的。对于连续随机变量，乘法规则则是用概率密度函数来表示的（第6.2.3节）。

在机器学习和贝叶斯统计中，我们经常在观察到其他随机变量的情况下，对未观察到的（潜在的）随机变量进行推断。假设我们对一个未观察到的随机变量$x$有一些先验知识$p(x)$，以及$x$与我们可以观察到的第二个随机变量$y$之间的某种关系$p(\boldsymbol{y}\mid\boldsymbol{x})$。如果我们观察到了$y$，我们可以使用贝叶斯定理根据观察到的$y$的值来得出关于$x$的一些结论。**贝叶斯定理（也称为贝叶斯规则或贝叶斯定律）**

(6.23)

$$\underbrace{p(\boldsymbol{x}\mid\boldsymbol{y})}_{\text{后验}}=\frac{\overbrace{p(\boldsymbol{y}\mid\boldsymbol{x})}^{\text{似然度}}\overbrace{p(\boldsymbol{x})}^{\text{先验}}}{\underbrace{p(\boldsymbol{y})}_{\text{证据}}}$$

是（6.22）中乘法规则的直接结果，因为

$$p(\boldsymbol{x},\boldsymbol{y})=p(\boldsymbol{x}\mid\boldsymbol{y})p(\boldsymbol{y})$$

(6.24)

以及

(6.25)

$$p(\boldsymbol{x},\boldsymbol{y})=p(\boldsymbol{y}\mid\boldsymbol{x})p(\boldsymbol{x})$$

所以

$$p(\boldsymbol{x}\mid\boldsymbol{y})p(\boldsymbol{y})=p(\boldsymbol{y}\mid\boldsymbol{x})p(\boldsymbol{x})\iff p(\boldsymbol{x}\mid\boldsymbol{y})=\frac{p(\boldsymbol{y}\mid\boldsymbol{x})p(\boldsymbol{x})}{p(\boldsymbol{y})}\:.$$

(6.26)

在（6.23）中，$p(x)$是先验，它包含了我们在观察到任何数据之前对未观察到的（潜在的）变量$x$的主观先验知识。我们可以选择任何对我们有意义的先验，但至关重要的是要确保先验在所有可能的$x$上都有非零的概率密度函数（或概率质量函数），即使它们非常罕见。

似然度$p(\boldsymbol{y}\mid x)$描述了$x$和$y$之间的关系，在离散概率分布的情况下，它是如果我们知道潜在变量$x$，则数据$y$出现的概率。请注意，似然度有时并不被视为$x$上的分布，而只是$y$上的分布（MacKay, 2003）。

后验$p(x\mid y)$是贝叶斯统计中我们感兴趣的量，因为它准确地表达了我们所关心的内容，即观察到$y$之后我们对$x$的了解。

(6.27)式中的量

$$p(\boldsymbol{y}):=\int p(\boldsymbol{y}\mid\boldsymbol{x})p(\boldsymbol{x})\mathrm{d}\boldsymbol{x}=\mathbb{E}_X[p(\boldsymbol{y}\mid\boldsymbol{x})]$$

是边缘似然/证据。式(6.27)的右侧使用了期望算子，我们将在第6.4.1节中定义它。根据定义，边缘似然是对(6.23)式的分子关于隐变量$x$的积分。因此，边缘似然与$x$无关，并且它确保了后验$p(\boldsymbol{x}\mid\boldsymbol{y})$是归一化的。边缘似然也可以被解释为在先验$p(x)$下的期望似然。除了后验的归一化外，边缘似然在贝叶斯模型选择中也起着重要作用，我们将在第8.6节中讨论这一点。由于(8.44)式中的积分，证据的计算通常很困难。

贝叶斯定理(6.23)允许我们反转由似然给出的$x$和$y$之间的关系。因此，贝叶斯定理有时被称为概率逆定理。我们将在第8.4节中进一步讨论贝叶斯定理。

**备注**：在贝叶斯统计中，后验分布是感兴趣的量，因为它包含了先验和数据中的所有可用信息。除了考虑整个后验分布外，还可以关注后验分布的一些统计量，如后验最大值，这将在第8.3节中讨论。然而，关注后验分布的一些统计量会导致信息丢失。如果我们从更大的背景来考虑，后验分布可以在决策系统中使用，并且拥有完整的后验分布可能非常有用，能够做出对扰动具有鲁棒性的决策。例如，在基于模型的强化学习背景下，Deisenroth等人（2015）表明，使用可能转换函数的完整后验分布会导致非常快速（数据/样本高效）的学习，而关注后验最大值则会导致持续的失败。因此，对于下游任务而言，拥有完整的后验分布可能非常有用。在第9章中，我们将在线性回归的背景下继续这一讨论。