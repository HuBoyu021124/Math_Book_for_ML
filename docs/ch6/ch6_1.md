## 6.1 概率空间的构建

概率论旨在定义一个数学结构来描述实验结果的随机性。例如，在抛掷一枚硬币时，我们无法确定结果，但通过大量抛掷硬币，我们可以观察到平均结果中的规律性。利用这种概率的数学结构，目标是进行自动化推理，从这个意义上说，概率是对逻辑推理的泛化（Jaynes, 2003）。

### 6.1.1 哲学问题

在构建自动化推理系统时，经典布尔逻辑不允许我们表达某些形式的合理推理。考虑以下场景：我们观察到A为假。我们发现B变得不那么可信，尽管从经典逻辑中无法得出这一结论。我们观察到B为真，似乎A又变得更为可信。我们每天都在使用这种形式的推理。比如，我们在等一位朋友，并考虑三种可能性：H1，她准时到达；H2，她被交通延误了；H3，她被外星人绑架了。当我们观察到朋友迟到时，我们必须从逻辑上排除H1。我们也倾向于认为H2更有可能，尽管逻辑上并不要求我们必须这样做。最后，我们可能会认为H3是可能的，但继续认为它非常不可能。那么，我们如何得出结论认为H2是最合理的答案？从这个角度看，“合理的概率论可以被视为布尔逻辑的一种泛化”。在机器学习的推理背景下，它经常被这样应用，以形式化并扩展自动化推理系统的设计。关于如何以真值概率论的假值为基础构建推理系统的进一步论证，可参见Pearl（1988）。

概率的哲学基础以及它应该如何以某种方式（Jaynes, 2003）与我们认为在逻辑上应该为真的事物相关联，这一问题被Cox研究过（Jaynes, 2003）。另一种思考方式是，如果我们精确地使用常识，最终会构建出概率。E. T. Jaynes（1922-1998）确定了三个数学标准，这些标准必须适用于所有可能性：

1. 可能性的程度由实数表示。

2. 这些数字必须基于常识的规则。

3. 所得推理必须是一致的，其中“一致”一词包含以下三层含义：

   (a) 一致性或无矛盾性：当可以通过不同方式达到相同结果时，在所有情况下都必须找到相同的可能性值。
   (b) 诚实性：必须考虑所有可用数据。
   (c) 可再现性：如果我们对两个问题的知识状态相同，那么我们必须为它们分配相同程度的可能性。

Cox-Jaynes定理证明了这些可能性足以定义适用于可能性$p$的普遍数学规则，直到通过任意单调函数进行变换。至关重要的是，这些规则就是概率的规则。

备注。在机器学习和统计学中，概率有两种主要解释：贝叶斯解释和频率解释（Bishop, 2006; Efron and Hastie, 2016）。贝叶斯解释使用概率来指定用户对某个事件发生的不确定性程度。它有时被称为“主观概率”或“信念程度”。频率解释则考虑感兴趣事件相对于发生事件总数的相对频率。当数据无限时，某事件的概率被定义为该事件的相对频率。

一些关于概率模型的机器学习文献使用了不严谨的记号和术语，这会造成困惑。本文也不例外。多个不同的概念都被称为“概率分布”，读者往往需要从上下文中分辨其含义。一个有助于理解概率分布的技巧是检查我们是在尝试对分类事物（离散随机变量）还是连续事物（连续随机变量）进行建模。我们在机器学习中解决的问题类型与我们是考虑分类模型还是连续模型密切相关。

### 6.1.2 概率与随机变量

在讨论概率时，经常会混淆三个不同的概念。首先是概率空间的概念，它使我们能够量化概率的想法。然而，我们大多不直接处理这个基本的概率空间。相反，我们处理的是随机变量（第二个概念），它将概率转移到一个更方便（通常是数值）的空间。第三个概念是与随机变量相关的分布或定律。我们将在本节中介绍前两个概念，并在6.2节中详细阐述第三个概念。

现代概率论基于Kolmogorov提出的一组公理（Grinstead and Snell, 1997; Jaynes, 2003），这些公理引入了样本空间、事件空间和概率测度这三个概念。概率空间模型用于模拟具有随机结果的现实世界过程（称为实验）。

**样本空间 $\Omega$**. 样本空间是实验所有可能结果的集合，通常表示为 $\Omega$。例如，连续两次抛硬币的样本空间为 $\{hh, tt, ht, th\}$，其中“h”表示“正面”，“t”表示“反面”。

**事件空间 A**. 事件空间是实验潜在结果的集合。如果实验结束时我们可以观察到某个特定结果 $\omega\in\Omega$ 是否在 $A$ 中，则样本空间 $\Omega$ 的子集 $A$ 就属于事件空间 $\mathcal{A}$。事件空间 $A$ 是通过考虑 $\Omega$ 的子集集合获得的，对于离散概率分布（第6.2.1节），$\mathcal{A}$ 通常是 $\Omega$ 的幂集。

**概率 $P$**. 对于每个事件 $A\in\mathcal{A}$，我们关联一个数 $P(A)$，它衡量了事件发生的概率或信念程度。$P(A)$ 被称为 $A$ 的概率。

单个事件的概率必须位于区间 [0,1] 内，样本空间 $\Omega$ 中所有结果的总概率必须为 1，即 $P(\Omega)=1$。给定一个概率空间 $(\Omega,\mathcal{A},P)$，我们希望用它来模拟一些现实世界的现象。在机器学习中，我们通常避免明确提及概率空间，而是指关注量的概率，我们用 $\mathcal{T}$ 来表示。在本书中，我们将 $\mathcal{T}$ 称为目标空间，并将 $\mathcal{T}$ 的元素称为状态。我们引入一个函数 $\bar{X}:\dot{\Omega}\to\mathcal{T}$，它接受 $\Omega$ 的一个元素（一个结果）并返回一个特定的关注量 $x$，即 $\mathcal{T}$ 中的一个值。从 $\Omega$ 到 $T$ 的这种关联/映射被称为随机变量。例如，在抛两枚硬币并计算正面朝上次数的情况下，随机变量 $X$ 映射到三个可能的结果：$X(hh)=2, X(ht)=1, X(th)=1,$ 和 $X(tt)=0$。在这个特定情况下，$\vec{\mathcal{T}}=\{0,1,2\}$，我们关注的是 $\mathcal{T}$ 元素上的概率。对于有限的样本空间 $\Omega$ 和有限的目标空间 $\mathcal{T}$，与随机变量对应的函数本质上是一个查找表。对于 $\mathcal{T}$ 的任何子集 $S\subseteq\mathcal{T}$，我们将 $P_X(S)\in[0,1]$（误解概率）与随机变量 $X$ 对应的特定事件相关联。示例 6.1 提供了术语的具体说明。

**备注** 上述样本空间 $\Omega$ 在不同的书中被称为不同的名称。$\Omega$ 的另一个常见名称是“状态空间”（Jacod and Protter, 2004），但状态空间有时保留用于指动态系统中的状态（Hasselblatt and Katok, 2003）。其他有时用于描述 $\Omega$ 的名称包括：“样本描述空间”、“可能性空间”和“事件空间”。

> 示例 6.1
>
> 我们假设读者已经熟悉计算事件集合的交集和并集的概率。对于更温和且包含许多例子的概率论介绍，可以在 Walpole 等人（2011）的第 2 章中找到。
>
> 考虑一个统计实验，我们模拟一个游乐场游戏，该游戏包括从一个袋子中抽取两枚硬币（放回原袋）。袋子中有来自美国（用 \$表示）和英国（用 £ 表示）的硬币，因为我们从袋子中抽取两枚硬币，所以总共有四种结果。这个实验的状态空间或样本空间 $\Omega$ 因此是 $(\mathfrak{S},\mathfrak{S}),(\mathfrak{S}, E),(E,\Phi),(E,E)$（注意：这里的符号可能有些不一致，通常我们会用更具体的符号如 $($, $), ($, £), (£, \$), (£, £) 来表示，但为了与原文保持一致，我们保留原符号）。假设袋子中硬币的组成是这样的：随机抽取一枚硬币得到 $ 的概率是 0.3。
>
> 我们感兴趣的事件是重复抽取中返回 \$ 的总次数。让我们定义一个随机变量 $X$，它将样本空间 $\Omega$ 映射到 $\mathcal{T}$，后者表示我们从袋子中抽取 \$ 的次数。从前面的样本空间可以看出，我们可以得到零次 $，一次 $，或两次 $，因此 $$\mathcal{T}=\{0,1,2\}$。随机变量 $X$（一个函数或查找表）可以表示如下表：
>
> $$
> \begin{aligned}
> X((\$,\$)) &= 2 \\
> X((\$,£)) &= 1 \\
> X((£,\$)) &= 1 \\
> X((£,£)) &= 0
> \end{aligned}
> $$
> 由于我们在抽取第二枚硬币之前将第一枚硬币放回袋子，这意味着两次抽取是相互独立的，我们将在第 6.4.5 节中讨论这一点。请注意，有两个实验结果映射到同一个事件，即只有其中一次抽取返回 $。因此，$X$ 的概率质量函数（第 6.2.1 节）由下式给出：
>
> $$
> \begin{aligned}
> &P(X=2) &&= P((\$,\$)) \\
> &&&= P(\$)\cdot P(\$) \\
> &&&= 0.3\cdot0.3=0.09 \\
> &P(X=1) &&= P((\$,£)\cup(£,\$)) \\
> &&&= P((\$,£))+P((£,\$)) \\
> &&&= 0.3\cdot(1-0.3)+(1-0.3)\cdot0.3=0.42 \\
> &P(X=0) &&= P((£,£)) \\
> &&&= P(£)\cdot P(£) \\
> &&&= (1-0.3)\cdot(1-0.3)=0.49
> \end{aligned}
> $$

在计算中，我们将两个不同的概念等同起来，即 $X$ 的输出概率和 $\Omega$ 中样本的概率。例如，在（6.7）中我们说 $P(X=0)=P((£,£))$。考虑随机变量 $X:\Omega\to\mathcal{T}$ 和一个子集 $S\subseteq\mathcal{T}$（例如，$\mathcal{T}$ 的一个单元素，如投掷两枚硬币时得到一个正面的结果）。令 $X^{-1}(S)$ 是 $S$ 在 $X$ 下的原像，即 $\Omega$ 中在 $X$ 下映射到 $S$ 的元素集合；${\omega\in\Omega:X(\omega)\in S}$。理解从 $\Omega$ 中的事件通过随机变量 $X$ 转换到概率的一种方式是将其与 $S$ 的原像的概率相关联（Jacod 和 Protter，2004）。对于 $S\subseteq\mathcal{T}$，我们使用以下符号：

$$P_{X}(S)=P(X\in S)=P(X^{-1}(S))=P({\omega\in\Omega:X(\omega)\in S})\:.$$
(6.8)

(6.8) 的左侧是我们感兴趣的可能结果集（例如，$=$ 的数量 = 1）的概率。通过随机变量 $X$，它将状态映射到结果，我们在 (6.8) 的右侧看到这是具有某种性质（例如，$S$ 包含 £, £）的状态集（在 $\Omega$ 中）的概率。我们说随机变量 $X$ 根据特定的概率分布 $P_X$ 分布，该分布定义了事件与随机变量结果概率之间的概率映射。换句话说，函数 $P_{X}$ 或等价地 $P\circ X^{- 1}$ 是随机变量 $X$ 的分布律或分布。

**备注**：目标空间，即随机变量 $X$ 的值域 $\mathcal{T}$，用于指示概率空间的类型，即 $T$ 随机变量。当 $\mathcal{T}$ 是有限或可数无限时，这被称为离散随机变量（第 6.2.1 节）。对于连续随机变量（第 6.2.2 节），我们只考虑 $\mathcal{T}=\mathbb{R}$ 或 $\mathcal{T}=\mathbb{R}^D$。

### 6.1.3 统计学

概率论和统计学经常被放在一起讨论，但它们关注的是不确定性的不同方面。对比它们的一种方式是考虑所研究的问题类型。使用概率论，我们可以考虑某个过程的模型，其中潜在的不确定性通过随机变量来捕捉，并利用概率规则来推导出所发生的事情。在统计学中，我们观察到某件事情已经发生，并试图找出解释这些观察结果的潜在过程。从这个意义上说，机器学习的目标更接近统计学，即构建一个能够充分表示数据生成过程的模型。我们可以利用概率规则来获得某些数据的“最佳拟合”模型。

机器学习系统的另一个方面是，我们关注泛化误差（见第8章）。这意味着我们实际上对系统在未来观察到的实例上的性能感兴趣，而这些实例与我们到目前为止已经看到的实例并不相同。对未来性能的这种分析依赖于概率论和统计学，其中大部分内容超出了本章将介绍的范围。有兴趣的读者可以查阅Boucheron等人（2013）以及Shalev-Shwartz和Ben-David（2014）的著作。我们将在第8章中进一步了解统计学。
