## 5.9 拓展阅读

关于矩阵微分的更多细节，以及对所需线性代数的简短回顾，可以在 Magnus and Neudecker（2007）中找到。自动微分有着悠久的历史，读者可以参考 Griewank and Walther（2003）、Griewank and Walther（2008）、Elliott（2009）及其中的参考文献。

在机器学习（以及其他学科）中，我们经常需要计算期望，即我们需要求解形如$$\mathbb{E}_{x}[f(x)] = \int f(x)p(x)\mathrm{d}x \displaystyle \tag{5.181}$$的积分。即使 $p(x)$ 的形式比较简单（例如 Gauss 分布），这个积分通常也没有解析解。然而使用 $f$ 的 Taylor 级数是找到近似解的一种方法。假设 $p(x)=\mathcal{N}(\boldsymbol{ \mu },\boldsymbol{ \Sigma })$ 是 Gauss 分布，那么在 $\boldsymbol{ \mu }$ 附近的一阶 Taylor 级数展开将非线性函数 $f$ 局部线性化。对于线性函数，如果 $p(x)$是 Gauss 分布，我们可以精确计算乘积均值和协方差（见6.5节）。这样的性质在 **扩展 Kalman 滤波（extended kalman filter, EKF）**（Maybeck，1979）和 **非线性系统（也称为“状态空间模型”）的在线状态估计** 中被大量应用。其他用于近似（5.181）中积分的确定性的方法包括无需梯度计算的 **无迹变换（unsecnted transform）**（Julier和Uhlmann，1997）或者使用二阶 Taylor 展开的（Hessian 矩阵）以对 $p(x)$ 进行局部 Gauss 近似的 **Laplace 近似**（MacKay，2003；Bishop，2006；Murphy，2002）。