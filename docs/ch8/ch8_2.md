## 8.2 经验风险最小化

在我们掌握了所有相关的数学知识之后，我们现在可以介绍学习的含义了。机器学习中的“学习”部分实质上就是基于训练数据来估计参数。在本节中，我们考虑预测器是一个函数的情况，而概率模型的情况将在第8.3节中讨论。我们将描述经验风险最小化的概念，这一概念最初是由支持向量机（第12章描述）的提出而普及的。然而，其一般原则具有广泛的适用性，使我们能够在不显式构建概率模型的情况下，探讨学习的本质。以下是四个主要的设计选择，我们将在以下小节中详细讨论：

8.2.1 我们允许预测器采用哪些函数集？

8.2.2 我们如何衡量预测器在训练数据上的表现好坏？

8.2.3 我们如何从仅训练数据中构建在未见过的测试数据上表现良好的预测器？

8.2.4 在模型空间中搜索的程序是什么？

### 8.2.1 函数假设类

假设我们得到$N$个样本$x_n\in\mathbb{R}^D$和对应的标量标签$y_n\in\mathbb{R}$。我们考虑监督学习的设置，其中我们获得样本对$(x_1,y_1),\ldots,(x_N,y_N)$。基于这些数据，我们希望估计一个预测器$f(\cdot,\boldsymbol{\theta}):\mathbb{R}^D\to\mathbb{R}$，它通过参数$\theta$进行参数化。我们希望能够找到一个好的参数$\theta^{*}$，以便很好地拟合数据，即
$$f(\boldsymbol{x}_{n},\boldsymbol{\theta}^{*})\approx y_{n}\quad\text{对于所有}\quad n=1,\ldots,N\:.$$
(8.3)

在本节中，我们使用符号$\hat{y}_n=f(x_n,\theta^*)$来表示预测器的输出。

备注：为了便于阐述，我们将以监督学习（即我们有标签）的角度来描述经验风险最小化。这简化了假设类和损失函数的定义。在机器学习中，选择一类参数化函数也很常见，例如仿射函数。

> **例8.1**
>
> 我们引入普通最小二乘回归问题来说明经验风险最小化。关于回归的更全面介绍将在第9章中给出。当标签$y_n$是实数值时，预测器函数类的一个流行选择是仿射函数集。我们通过向$x_n$添加一个额外的单位特征$x^{(0)}=1$，即$x_n=[1,x_n^{(1)},x_n^{(2)},\ldots,x_n^{(D)}]^\top$，来更简洁地表示仿射函数。相应地，机器学习参数向量是$\boldsymbol{\theta}=[\theta_0,\theta_1,\theta_2,\ldots,\theta_D]^\top$，这使得我们可以将预测器写为线性函数
> $$f(x_n,\boldsymbol{\theta})=\boldsymbol{\theta}^\top\boldsymbol{x}_n\:.$$
> (8.4)
>
> 这个线性预测器等价于仿射模型
>
> (8.5)
> $$f(\boldsymbol{x}_n,\boldsymbol{\theta})=\theta_0+\sum_{d=1}^D\theta_dx_n^{(d)}\:.$$
>
> 预测器以表示单个样本$x_n$的特征向量为输入，并产生实数值输出，即$f:\mathbb{R}^{D+1}\to\mathbb{R}$。本章前面的图表中，预测器是一条直线，这意味着我们假设了一个仿射函数。
>
> 除了线性函数外，我们可能还希望考虑非线性函数作为预测器。神经网络领域的最新进展使得能够高效地计算更复杂的非线性函数类。

给定这类函数，我们想要寻找一个好的预测器。现在，我们转向经验风险最小化的第二个要素：如何测量预测器与训练数据的匹配程度。

### 8.2.2 训练损失函数

考虑一个特定样本的标签$y_n$，以及我们基于$x_n$做出的相应预测$\hat{y}_n$。为了定义什么是良好的数据拟合，我们需要指定一个损失函数$\ell(y_n,\hat{y}_n)$，该函数以真实标签和预测值为输入，并产生一个非负数值（称为损失），表示我们在该特定预测上犯了多大的错误。我们寻找一个好的参数向量$\theta^*$的目标是最小化在$N$个训练样本集上的平均损失。

机器学习中的一个常见假设是，样本集$(x_1,y_1),\ldots,(\boldsymbol{x}_N,y_N)$是独立同分布的。独立（第6.4.5节）一词意味着两个数据点$(\boldsymbol x_i,y_i)$和$(\boldsymbol x_j,y_j)$在统计上互不依赖，这意味着经验均值是总体均值的良好估计（第6.4.1节）。这意味着我们可以使用训练数据上损失的经验均值。对于给定的训练集$\{(\boldsymbol x_1,y_1),\ldots,(\boldsymbol x_N,y_N)\}$，我们引入示例矩阵$X:=[x_1,\ldots,x_N]^\top\in\mathbb{R}^{N\times D}$和标签向量$y:=[y_1,\ldots,y_N]^\top\in\mathbb{R}^N$的符号。使用这种矩阵符号，平均损失由下式给出：
$$\mathbf{R}_{\mathrm{emp}}(f,\boldsymbol{X},\boldsymbol{y})=\frac{1}{N}\sum_{n=1}^{N}\ell(y_{n},\hat{y}_{n})\:,$$
(8.6)

其中$\hat{y}_n=f(\boldsymbol{x}_n,\boldsymbol{\theta})$。式（8.6）被称为经验风险，它取决于三个参数：预测器$f$和数据$X,y$。这种学习策略通常被称为经验风险最小化。

> **例 8.2（最小二乘损失）**
>
> 继续最小二乘回归的示例，我们指定使用平方损失$\ell(y_n,\hat{y}_n)=(y_n-\hat{y}_n)^2$来衡量训练过程中犯错的代价。我们希望最小化经验风险（8.6），即数据上损失的平均值
>
> (8.7)
> $$\min_{\boldsymbol{\theta}\in\mathbb{R}^D}\frac{1}{N}\sum_{n=1}^N(y_n-f(\boldsymbol{x}_n,\boldsymbol{\theta}))^2,$$
>
> 其中我们用预测器$\hat{y}_n=f(\boldsymbol{x}_n,\boldsymbol{\theta})$进行了替换。通过选择线性预测器$f(\boldsymbol{x}_n,\boldsymbol{\theta})=\boldsymbol{\theta}^\top\boldsymbol{x}_n$，我们得到优化问题
>
> $$\min_{\boldsymbol{\theta}\in\mathbb{R}^D}\frac{1}{N}\sum_{n=1}^N(y_n-\boldsymbol{\theta}^\top\boldsymbol{x}_n)^2\:.$$
> (8.8)
>
> 这个方程可以等价地用矩阵形式表示
>
> (8.9)
> $$\min_{\boldsymbol{\theta}\in\mathbb{R}^{D}}\frac{1}{N}\left\|\boldsymbol{y}-\boldsymbol{X}\boldsymbol{\theta}\right\|^{2}\:.$$
>
> 这被称为最小二乘问题。通过求解正规方程，我们可以得到一个闭式解析解，这将在第9.2节中讨论。

我们并不关心仅在训练数据上表现良好的预测器。相反，我们寻求的是在未见的测试数据上表现良好（风险低）的预测器。更正式地说，我们感兴趣的是找到一个预测器$f$（参数固定），该预测器能够最小化预期风险

(8.10)
$$\mathbf{R}_{\mathrm{true}}(f)=\mathbb{E}_{x,y}[\ell(y,f(\boldsymbol{x}))]\:,$$
其中$y$是标签，$f(x)$是基于样本$x$的预测。符号$\mathbf{R}_{\text{true}}(f)$表示如果我们拥有无限量的数据，这就是真正的风险。该期望是针对所有可能的数据和标签的（无限）集合。从我们通常希望最小化预期风险的愿望中，产生了两个实际问题，我们将在以下两个小节中讨论：

* 我们应该如何改变训练过程以使其具有良好的泛化能力？
* 我们如何从（有限）数据中估计预期风险？

备注。许多机器学习任务都指定了相关的性能指标，例如预测的准确性或均方根误差。性能指标可能更复杂，对成本敏感，并捕获特定应用的详细信息。原则上，用于经验风险最小化的损失函数的设计应直接对应于机器学习任务指定的性能指标。但在实践中，损失函数的设计与性能指标之间往往存在不匹配。这可能是由于实现简便性或优化效率等问题导致的。

### 8.2.3 正则化以减少过拟合

本节介绍了一种对经验风险最小化的补充方法，使其能够很好地泛化（即近似最小化预期风险）。回顾一下，训练机器学习预测器的目的是使我们在未见过的数据上也能表现良好，即预测器具有很好的泛化能力。我们通过保留整个数据集的一部分来模拟这种未见过的数据，这部分数据被称为测试集。给定一个足够丰富的预测器$f$的函数类，我们基本上可以记住训练数据以获得零经验风险。虽然这对于最小化训练数据上的损失（因此是风险）来说很好，但我们不会期望预测器在未见过的数据上有很好的泛化能力。在实践中，我们只有有限的数据集，因此我们将数据分为训练集和测试集。训练集用于拟合模型，而测试集（在训练过程中机器学习算法未见过）用于评估泛化性能。重要的是，用户在观察测试集后不应回到训练的新一轮循环中。我们使用下标train和test来分别表示训练集和测试集。我们将在第8.2.4节中重新讨论使用有限数据集来评估预期风险的想法。

事实证明，经验风险最小化可能导致“过拟合”，即预测器过于紧密地拟合训练数据，而不能很好地泛化到新数据（Mitchell, 1997）。这种在训练集上平均损失很小但在测试集上平均损失很大的普遍现象，往往发生在我们拥有少量数据和复杂假设类时。对于特定的预测器$f$（参数固定），当过拟合现象发生时，来自训练数据的风险估计$\mathbf{R}_\mathrm{emp}(f,X_\mathrm{train},y_\mathrm{train})$会低估预期风险$\mathbf{R}_\mathrm{true}(f)$。由于我们使用测试集上的经验风险$\mathbf{R}_{\mathrm{emp}}(f,\boldsymbol{X}_{\mathrm{test}},\boldsymbol{y}_{\mathrm{test}})$来估计预期风险$\mathbf{R}_\mathrm{true}(f)$，如果测试风险远大于训练风险，这就是过拟合的迹象。我们将在第8.3.3节中重新讨论过拟合的概念。

因此，我们需要通过引入惩罚项来以某种方式偏向寻找经验风险最小化的最小化器，这使得优化器更难返回一个过于灵活的预测器。在机器学习中，这个惩罚项被称为正则化。正则化是在经验风险最小化的准确解与解的大小或复杂性之间做出妥协的一种方式。

> **示例 8.3（正则化最小二乘法）**
>
> 正则化是一种方法，用于阻止优化问题中出现复杂或极端的解决方案。最简单的正则化策略是通过添加一个仅涉及$\theta$的惩罚项，将前一个示例中的最小二乘问题
>
> $$ \min_{\boldsymbol{\theta}}\frac{1}{N}\left\|\boldsymbol{y}-\boldsymbol{X}\boldsymbol{\theta}\right\|^2. $$
> (8.11)
>
> 替换为“正则化”问题：
>
> $$ \min_{\theta}\frac{1}{N}\left\|y-X\theta\right\|^{2}+\lambda\left\|\theta\right\|^{2}. $$
> (8.12)
>
> 其中，附加项$\|\theta\|^2$被称为正则化项，而参数$\lambda$被称为正则化参数。正则化参数在训练集上的损失最小化和参数$\theta$的幅度之间进行了权衡。当出现过拟合时，参数值的幅度往往会变得相对较大（Bishop, 2006）。

 正则化项有时被称为惩罚项，它促使向量*θ*更接近原点。正则化的思想也出现在概率模型中，作为参数的先验概率。回顾第6.6节，为了使后验分布与先验分布具有相同的形式，先验和似然需要是共轭的。我们将在第8.3.2节中重新探讨这个思想。在第12章中，我们将看到正则化的思想与大间隔的思想是等价的。 

### 8.2.4 交叉验证以评估泛化性能

我们在上一节中提到，我们通过将预测器应用于测试数据来估计泛化误差以衡量其性能。这些数据有时也被称为验证集。验证集是我们保留在外的可用训练数据的一个子集。这种方法的一个实际问题是数据量有限，而理想情况下我们希望使用尽可能多的可用数据来训练模型。这将要求我们保持验证集$\mathcal{V}$较小，但这会导致预测性能的估计具有噪声（高方差）。解决这些相互矛盾的目标（大训练集、大验证集）的一个方法是使用交叉验证。K折交叉验证有效地将数据分成$K$个部分，其中$K-1$个部分形成训练集$\mathcal{R}$，最后一个部分作为验证集$\mathcal{V}$（类似于前面概述的想法）。交叉验证遍历（理想情况下）所有将部分分配给$\mathcal{R}$和$\mathcal{V}$的组合；见图8.4。此过程针对验证集的$K$种选择重复进行，并对$K$次运行的模型性能进行平均。

![1723900862136](../attachments/8.4.png)

**图8.4k倍交叉验证。数据集被分为K = 5个块，其中K−1作为训练集（蓝色），一个作为验证集（橙色孵化）。**

我们将数据集分为两个不重叠的集合$\mathcal{D}=\mathcal{R}\cup\mathcal{V}$（$\mathcal{R}\cap\mathcal{V}=\emptyset$），其中$\mathcal{V}$是验证集，我们在$\mathcal{R}$上训练模型。训练后，我们在验证集$\mathcal{V}$上评估预测器$f$的性能（例如，通过计算验证集上训练模型的均方根误差（RMSE））。更准确地说，对于每个分区$k$，训练数据$\mathcal{R}^{(k)}$产生一个预测器$f^{(k)}$，然后将其应用于验证集$\mathcal{V}^{(k)}$以计算经验风险$R(f^{(k)},\mathcal{V}^{(k)})$。我们遍历验证集和训练集的所有可能分区，并计算预测器的平均泛化误差。交叉验证近似于期望泛化误差

$$\mathbb{E}_{\mathcal{V}}[R(f,\mathcal{V})]\approx\frac{1}{K}\sum_{k=1}^{K}R(f^{(k)},\mathcal{V}^{(k)})$$
(8.13)

其中$R(f^{(k)},\mathcal{V}^{(k)})$是预测器$f^{(k)}$在验证集$\mathcal{V}^{(k)}$上的风险（例如，RMSE）。该近似有两个来源：首先，由于有限的训练集，导致不是最佳的$f^{(k)}$；其次，由于有限的验证集，导致对风险$R(f^{(k)},\mathcal{V}^{(k)})$的估计不准确。K折交叉验证的一个潜在缺点是训练模型$K$次的计算成本很高，如果训练成本在计算上很昂贵，这可能会成为负担。在实践中，仅查看直接参数通常是不够的。例如，我们需要探索多个复杂性参数（例如，多个正则化参数），这些可能不是模型的直接参数。根据这些超参数评估模型的质量，可能会导致训练次数与模型参数数量成指数关系。可以使用嵌套交叉验证（第8.6.1节）来搜索良好的超参数。

然而，交叉验证是一个令人尴尬的并行问题，即将问题分离为多个并行任务所需的努力很少。在拥有足够的计算资源（例如，云计算、服务器集群）的情况下，交叉验证所需的时间不会比单次性能评估更长。在本节中，我们了解到经验风险最小化基于以下概念：函数假设类、损失函数和正则化。在第8.3节中，我们将看到使用概率分布来替代损失函数和正则化想法的效果。

### 8.2.5 进阶阅读

由于经验风险最小化（Vapnik, 1998）的原始发展采用了大量理论性语言，随后的许多发展也多为理论性。这一研究领域被称为统计学习理论（Vapnik, 1999; Evgeniou et al., 2000; Hastie et al., 2001; von Luxburg and Schölkopf, 2011）。一本基于理论基础并开发了高效学习算法的最新机器学习教科书是Shalev-Shwartz和Ben-David（2014）所著。

正则化概念起源于不适定逆问题的求解（Neumaier, 1998）。本文介绍的方法称为Tikhonov正则化，并且有一个与之密切相关的约束版本，称为Ivanov正则化。Tikhonov正则化与偏差-方差权衡和特征选择（Bühlmann and Van De Geer, 2011）有着深厚的联系。交叉验证的替代方法是自助法和刀切法（Efron and Tibshirani, 1993; Davidson and Hinkley, 1997; Hall, 1992）。

将经验风险最小化（第8.2节）视为“无概率”是不正确的。存在一个潜在的未知概率分布$p(\boldsymbol x,y)$，它控制着数据的生成。然而，经验风险最小化的方法对该分布的选择是不可知的。这与明确要求知道$p(\boldsymbol{x},y)$的标准统计方法形成对比。此外，由于分布是样本$x$和标签$y$的联合分布，标签可能是非确定性的。与标准统计不同，我们不需要为标签$y$指定噪声分布。


