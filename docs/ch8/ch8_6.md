## 8.6 模型选择

在机器学习中，我们往往需要做出高层次的建模决策，这些决策对模型的性能有着至关重要的影响。我们所做的选择（例如，似然函数的形式）会影响模型中自由参数的数量和类型，进而也影响模型的灵活性和表达能力。更复杂的模型在某种意义上更加灵活，因为它们能够用来描述更多的数据集。例如，一个1次多项式（即一条直线$y=a_0+a_1x$）只能用来描述输入$x$和观测值$y$之间的线性关系。而通过将$a_2$设为0（即二次项系数为0），我们可以得到一个2次多项式，它除了能描述线性关系外，还能描述输入和观测值之间的二次关系。

现在，人们可能会认为，由于非常灵活的模型更具表达力，因此它们通常比简单的模型更受青睐。但一个普遍的问题是，在训练时，我们只能使用训练集来评估模型的性能并学习其参数。然而，我们真正关心的并不是模型在训练集上的表现。在第8.3节中，我们已经看到，最大似然估计可能会导致过拟合，尤其是在训练数据集较小时。理想情况下，我们的模型（也）应该在测试集上表现良好（而测试集在训练时是不可用的）。因此，我们需要一些机制来评估模型对未见过的测试数据的泛化能力。模型选择正是关注于这一问题。

![1723947388707](../attachments/8.13.png)

<center>图8.13：嵌套的交叉验证。我们进行了两个层次的k倍交叉验证。</center>

### 8.6.1 嵌套交叉验证

我们已经看到了一种（在第8.2.4节中的交叉验证）可用于模型选择的方法。回顾一下，交叉验证通过反复将数据集拆分为训练集和验证集来估计泛化误差。我们可以再次应用这个想法，即对于每次拆分，我们可以再进行一轮交叉验证。这有时被称为嵌套交叉验证；见图8.13。内层用于估计在内部验证集上特定模型或超参数选择的性能。外层则用于估计内层循环选择的最佳模型选择方案的泛化性能。我们可以在内层循环中测试不同的模型和超参数选择。为了区分这两个层次，通常将用于估计泛化性能的集合称为测试集，而将用于选择最佳模型的集合称为验证集。内层循环通过在验证集上的经验误差来近似给定模型的泛化误差的期望值（8.39），即：

$$\mathbb{E}_{\mathcal{V}}[\boldsymbol{R}(\mathcal{V}\mid M)]\approx\frac{1}{K}\sum_{k=1}^{K}\boldsymbol{R}(\mathcal{V}^{(k)}\mid M)\:,$$
(8.39)

其中，$\boldsymbol{R}(\mathcal{V}\mid M)$是模型$M$在验证集$\mathcal{V}$上的经验风险（例如，均方根误差）。我们对所有模型重复此过程，并选择表现最佳的模型。请注意，交叉验证不仅为我们提供了预期的泛化误差，我们还可以获得高阶统计量，例如标准误差，它是对均值估计的不确定性的一种估计。一旦选择了模型，我们就可以在测试集上评估其最终性能。

![1723947623541](../attachments/8.14.png)


**图8.14贝叶斯推理体现了奥卡姆剃刀原则。横轴描述了所有可能的数据集的空间d。证据（纵轴）评估了一个模型对可用数据的预测程度。由于p（D | Mi）需要集成到1中，所以我们应该选择证据最大的模型。改编自MacKay（2003）。**


### 8.6.2 贝叶斯模型选择

模型选择有许多方法，本节将介绍其中一些。一般来说，它们都在尝试在模型复杂性和数据拟合度之间做出权衡。我们假设简单模型比复杂模型更不易过拟合，因此模型选择的目标是找到能够合理解释数据的最简单模型。这个概念也被称为奥卡姆剃刀原则。

**奥卡姆剃刀原则**

备注：如果我们把模型选择视为一个假设检验问题，那么我们正在寻找的是与数据一致的最简单假设（Murphy, 2012）。

$\diamondsuit$

有人可能会考虑在模型上放置一个先验，以偏好更简单的模型。然而，这并非必要：在贝叶斯概率的应用中，“自动奥卡姆剃刀”是定量体现的（Smith 和 Spiegelhalter, 1980; Jefferys 和 Berger, 1992; MacKay, 1992）。图8.14（改编自MacKay, 2003）给出了一个基本直觉，解释了为什么复杂且极具表达力的模型在建模给定数据集$\mathcal{D}$时可能不是一个较优选择。让我们将水平轴视为代表所有可能数据集$\mathcal{D}$的空间的预测。如果我们关注的是给定数据$\mathcal{D}$下模型$M_i$的后验概率$p(M_i\mid\mathcal{D})$的量化表示，我们可以使用贝叶斯定理。假设所有模型上的先验$p(M)$是均匀的，贝叶斯定理会根据模型预测已发生数据的程度来奖励模型，即需要整合/求和到1。

给定模型$M_i$下数据$\mathcal{D}$的预测，即$p(\mathcal{D}\mid M_i)$，被称为$M_i$的证据。一个简单的模型$M_1$只能预测一小部分数据集，这由$p(\mathcal{D}\mid M_1)$表示；一个更强大的模型$M_2$（例如，具有比$M_1$更多的自由参数）能够预测更多种类的数据集。然而，这意味着$M_2$在区域$C$中对数据集的预测不如$M_1$。假设这两个模型的先验概率是相等的。那么，如果数据集落在区域$C$中，则较弱的模型$M_1$是更可能的模型。

在本章前面，我们论证了模型需要能够解释数据，即应该有一种方法可以从给定模型中生成数据。此外，如果模型已经从数据中得到了适当的学习，那么我们期望生成的数据应该与经验数据相似。为此，将模型选择表述为分层推理问题是很有帮助的，这允许我们计算模型上的后验分布。

让我们考虑有限数量的模型$M=\{M_1,\ldots,M_K\}$，其中每个模型$M_k$都拥有参数$\theta_k$。在贝叶斯模型选择中，我们在模型集上放置一个先验$p(M)$。允许我们从该模型生成数据的相应生成过程是

$$\begin{array}{c}M_k\sim p(M)\\\theta_k\sim p(\theta\mid M_k)\\\mathcal{D}\sim p(\mathcal{D}\mid\theta_k)\end{array}$$
(8.40) (8.41) (8.42)

![1723948030250](../attachments/8.15.png)

<center>图8.15贝叶斯模型选择中的层次生成过程说明。我们在一组模型上放置一个先验的p (M)。对于每个模型，在相应的模型参数上都有一个分布p（θ | M），用于生成数据D。</center>

并且如图8.15所示。给定一个训练集$\mathcal{D}$，我们应用贝叶斯定理并计算模型上的后验分布为

(8.43)
$$p(M_{k}\mid\mathcal{D})\propto p(M_{k})p(\mathcal{D}\mid M_{k})\:.$$
注意，这个后验分布不再依赖于模型参数$\theta_k$，因为在贝叶斯设置中它们已经被积分掉了，即
$$p(\mathcal{D}\mid M_{k})=\int p(\mathcal{D}\mid\boldsymbol{\theta}_{k})p(\boldsymbol{\theta}_{k}\mid M_{k})d\boldsymbol{\theta}_{k}\:,$$
(8.44)

其中$p(\boldsymbol{\theta}_k\mid M_k)$是模型$M_k$的参数$\theta_k$的先验分布。(8.44)项被称为模型证据或边缘似然。从(8.43)中的后验分布中，我们确定最大后验(MAP)估计

(8.45)
$$M^*=\arg\max_{M_k}p(M_k\mid\mathcal{D})\:.$$

如果采用均匀先验$p(M_k)=\frac1K$，即给予每个模型相等的（先验）概率，那么确定模型上的MAP估计就等价于选择使模型证据(8.44)最大化的模型。

**备注（似然与边缘似然）**：似然与边缘似然（证据）之间存在一些重要差异：虽然似然容易过拟合，但边缘似然通常不会，因为模型参数已经被边缘化（即我们不再需要拟合参数）。此外，边缘似然自动体现了模型复杂性和数据拟合度之间的权衡（奥卡姆剃刀原则）。

### **8.6.3 模型比较的贝叶斯因子**

考虑在给定数据集$\mathcal{D}$的情况下，比较两个概率模型$M_1, M_2$的问题。如果我们计算后验概率$p(M_1\mid\mathcal{D})$和$p(M_2\mid\mathcal{D})$，则可以计算后验概率的比率

(8.46)
$$\underbrace{\frac{p(M_1\mid\mathcal{D})}{p(M_2\mid\mathcal{D})}}_{\text{后验比率}}=\frac{\frac{p(\mathcal{D}\mid M_1)p(M_1)}{p(\mathcal{D})}}{\frac{p(\mathcal{D}\mid M_2)p(M_2)}{p(\mathcal{D})}}=\underbrace{\frac{p(M_1)}{p(M_2)}}_{\text{先验比率}}\underbrace{\frac{p(\mathcal{D}\mid M_1)}{p(\mathcal{D}\mid M_2)}}_{\text{贝叶斯因子}}\:.$$

后验概率的比率也被称为后验比率。等式(8.46)右侧的第一个分数，即先验比率，衡量了我们的先验（初始）信念在多大程度上偏向于$M_1$而非$M_2$。边缘似然（右侧第二个分数）的比率被称为**贝叶斯因子**，它衡量了与$M_2$相比，数据$D$被$M_1$预测得有多好。

**备注**。杰弗里斯-林德利悖论指出，“由于复杂模型在先验分布较为分散的情况下的数据概率将非常小，因此贝叶斯因子总是偏向于更简单的模型”（Murphy, 2012）。这里，扩散先验指的是一种不偏向特定模型的先验分布，即在该先验下，许多模型理论上都是合理的。

$\diamondsuit$

如果我们选择模型上的均匀先验，则(8.46)中的先验比率项为1，即后验比率就是边缘似然（贝叶斯因子）的比率

$$\frac{p(\mathcal{D}\mid M_1)}{p(\mathcal{D}\mid M_2)}\:.$$
(8.47)

如果贝叶斯因子大于1，我们选择模型$M_1$，否则选择模型$M_2$。与频率统计类似，关于在结果的“显著性”之前应考虑的比率大小， 存在相应的指导原则。（Jeffreys, 1961）。

**备注（计算边缘似然）**。边缘似然在模型选择中扮演着重要角色：我们需要计算贝叶斯因子(8.46)和模型上的后验分布(8.43)。不幸的是，计算边缘似然需要我们求解一个积分(8.44)。这个积分通常无法解析求解，因此我们必须求助于近似技术，例如数值积分（Stoer and Burlirsch, 2002）、使用Monte Carlo方法的随机近似（Murphy, 2012），或贝叶斯Monte Carlo技术（O'Hagan, 1991; Rasmussen and Ghahramani, 2003）。

然而，也有一些特殊情况可以求解。在6.6.1节中，我们讨论了共轭模型。如果我们选择共轭参数先验$p(\boldsymbol{\theta})$，则可以以闭合形式计算边缘似然。在第9章中，我们将在线性回归的上下文中正是这样做。

$\diamondsuit$

本章我们已经简要介绍了机器学习的基本概念。在本书的其余部分，我们将看到第8.2、8.3和8.4节中三种不同风格的学习如何应用于机器学习的四大支柱（回归、降维、密度估计和分类）。

### 8.6.4 拓展阅读

我们在本节的开头提到，存在一些高级建模选择，它们会影响模型的性能。这些例子包括：

* 回归设置中多项式的次数
* 混合模型中的组件数量
* （深度）神经网络的网络架构
* 支持向量机中的核函数类型
* 主成分分析（PCA）中潜在空间的维度
* 优化算法中的学习率（调度）

Rasmussen和Ghahramani（2001）指出，自动的奥卡姆剃刀原则并不一定会惩罚模型中的参数数量，但它确实在函数复杂度方面起作用。他们还表明，自动的奥卡姆剃刀原则也适用于具有许多参数的贝叶斯非参数模型，例如高斯过程。

如果我们关注最大似然估计，那么存在许多用于模型选择的启发式方法，这些方法可以阻止过拟合。它们被称为信息准则，我们选择具有最大值的模型。赤池信息量准则（AIC）（Akaike, 1974）

(8.48)
$$\log p(x\mid\boldsymbol{\theta})-M$$

通过添加一个惩罚项来补偿具有大量参数的更复杂模型的过拟合，从而校正最大似然估计的偏差。这里，$M$是模型参数的数量。AIC估计了给定模型所损失的相对信息量。贝叶斯信息准则（BIC）（Schwarz, 1978）

(8.49)
$$\log p(\boldsymbol{x})=\log\int p(\boldsymbol{x}\mid\boldsymbol{\theta})p(\boldsymbol{\theta})\mathrm{d}\boldsymbol{\theta}\approx\log p(\boldsymbol{x}\mid\boldsymbol{\theta})-\frac{1}{2}M\log N$$

可用于指数族分布。这里，$N$是数据点的数量，$M$是参数的数量。BIC对模型复杂度的惩罚比AIC更重。

